{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先梳理几个术语的区别：`Graph Embedding`, `Graph Neural Network`, `Graph Convolutional Network`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Embedding: 属于表示学习的范畴，通常有两个层次的含义：\n",
    "1. 将图中节点表示成低维、实值、稠密的向量形式，用于节点分类等等\n",
    "2. 将整个图表示成低维、实值、稠密的向量形式，用来对整个图结构进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图嵌入的方式有以下三种：\n",
    "1. 矩阵分解： 将节点间的关系用矩阵形式表达，分解矩阵得到嵌入向量，常用的矩阵有邻接矩阵、拉普拉斯矩阵、节点转移概率矩阵和节点属性矩阵等。\n",
    "2. DeepWalk： 将节点看做单词，随机游走的节点序列看做句子，然后将其作为word2vec的输入，得到节点的嵌入表示\n",
    "3. Graph Neural Network： 图神经网络可以应用于图嵌入来得到图或者节点的向量表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类比CNN的卷积操作，图神经网络的卷积操作是什么样呢，我们接下来就来看看图神经网络下特征的提取过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先定义一个图，对于图$G = (V, E)$, $V$是节点的集合，$E$是边的集合，对于图中每一个节点$i(i=1,\\dots,N)$,均有对应的特征向量$x_i$。整张图的特征用矩阵$X_{N*D}$,其中$N$表示图中的节点数，$D$表示每个节点的特征数，即特征向量的维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图还有几个比较重要的矩阵：\n",
    "1. 邻接矩阵：Adjacency matrix\n",
    "2. 度矩阵：Degree matrix\n",
    "3. Laplacian matrix： $L = D - A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们举一个无向图的例子，看一下各个量具体是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图的特征表示\n",
    "X = torch.tensor([\n",
    "    [1, 3, 5],\n",
    "    [1, 4, 9],\n",
    "    [3, 4, 9],\n",
    "    [3, 5, 7],\n",
    "    [5, 8, 3],\n",
    "    [6, 9, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#度矩阵\n",
    "D = torch.tensor([\n",
    "    [2, 0, 0, 0, 0, 0], \n",
    "    [0, 3, 0, 0, 0, 0],\n",
    "    [0, 0, 2, 0, 0, 0],\n",
    "    [0, 0, 0, 3, 0, 0],\n",
    "    [0, 0, 0, 0, 3, 0],\n",
    "    [0, 0, 0, 0, 0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#邻接矩阵\n",
    "A = torch.tensor([\n",
    "    [0, 1, 0, 0, 1, 0], \n",
    "    [1, 0, 1, 0, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, -1,  0,  0, -1,  0],\n",
       "        [-1,  3, -1,  0, -1,  0],\n",
       "        [ 0, -1,  2, -1,  0,  0],\n",
       "        [ 0,  0, -1,  3, -1, -1],\n",
       "        [-1, -1,  0, -1,  3,  0],\n",
       "        [ 0,  0,  0, -1,  0,  1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Laplacian Matric\n",
    "L = D - A\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任何一个卷积层都可以用下面的非线性函数表示：\n",
    "$$H^{l+1} = f(H^l, A)$$\n",
    "其中，$H^l$表示第$l$层的输出，也就是第$l+1$层的输入，$H^{l+1}$表示第$l+1$层的输出,$A$表示邻接矩阵,不同的$f$实现方式实现不同的图卷积层\n",
    "\n",
    "接下来我们就介绍几种$f$，然后根据其中一个$f$来构建卷积层："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实现一**：$$H^{l+1} = \\sigma(AH^lW^l)$$\n",
    "其中$W^l$表示第$l$层的权重参数矩阵，$\\sigma(\\cdot)$为非线性激活函数，例如ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 12, 12],\n",
       "        [ 9, 15, 17],\n",
       "        [ 4,  9, 16],\n",
       "        [14, 21, 12],\n",
       "        [ 5, 12, 21],\n",
       "        [ 3,  5,  7]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第一层输入特征为X，我们采用简单地方法来卷积\n",
    "A.mm(X)           #未考虑节点对自身的影响，也没有对邻接矩阵进行规范化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实现二**：$$H^{l+1} = \\sigma(LH^lW^l)$$\n",
    "其中$W^l$表示第$l$层的权重参数矩阵，$\\sigma(\\cdot)$为非线性激活函数，例如ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4,  -6,  -2],\n",
       "        [ -6,  -3,  10],\n",
       "        [  2,  -1,   2],\n",
       "        [ -5,  -6,   9],\n",
       "        [ 10,  12, -12],\n",
       "        [  3,   4,  -7]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尝试第二种方式\n",
    "L.mm(X)        #考虑了节点对自身的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实现三**：$$H^{l+1} = \\sigma(D^{-1/2}\\hat{A}D^{-1/2}H^lW^l)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000, -3.0000, -1.0000],\n",
       "        [-2.0000, -1.0000,  3.3333],\n",
       "        [ 1.0000, -0.5000,  1.0000],\n",
       "        [-1.6667, -2.0000,  3.0000],\n",
       "        [ 3.3333,  4.0000, -4.0000],\n",
       "        [ 3.0000,  4.0000, -7.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尝试第三种方法\n",
    "inverse_D = torch.inverse(D.float())\n",
    "inverse_D.mm(L.float()).mm(X.float())        #做了归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, use_bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        #定义权重矩阵W\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()    #这里使用自定义的参数初始化方式\n",
    "    def reset_parameters(self):\n",
    "        #自定义的参数初始化方式\n",
    "        init.kaiming_uniform_(self.weight)\n",
    "        if self.use_bias:\n",
    "            init.zeros_(self.bias)\n",
    "            \n",
    "    def forward(self, adjacency, input_feature):\n",
    "        \"\"\"\n",
    "        邻接矩阵是稀疏矩阵，所以使用稀疏矩阵乘法\n",
    "        \n",
    "        Args:\n",
    "             adjacency: torch.sparse.FloatTensor   邻接矩阵\n",
    "             input_feature: torch.Tensor   输入特征\n",
    "             \n",
    "        \"\"\"\n",
    "        support = torch.mm(input_feature, self.weight) #XW\n",
    "        output = torch.sparse.mm(adjacency, support)\n",
    "        if self.use_bias:\n",
    "            output += self.bias\n",
    "        return output\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.input_dim) + ' -> ' + str(self.output_dim) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面的卷积层，我们就可以构建模型了，下面我们定义一个包含两层`GraphConvolution`的模型:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class GcnNet(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个包含两层GraphConvolution的模型\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(GcnNet, self).__init__()\n",
    "        self.conv1 = GraphConvolution(input_dim, 16)\n",
    "        self.conv2 = GraphConvolution(16, 7)\n",
    "        \n",
    "    def forward(self, adjacency, feature):\n",
    "        h = F.relu(self.conv1(adjacency, feature))\n",
    "        logits = self.conv2(adjacency, h)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们结合图神经网络的经典数据集`cora`来走一遍流程：\n",
    "\n",
    "`Cora`数据集由许多机器学习领域的`paper`构成，这些`paper`被分为7个类别：\n",
    "- Case_Based\n",
    "- Genetic_Algorithms\n",
    "- Neural_Networks\n",
    "- Probabilistic_Methods\n",
    "- Reinforcement_Learning\n",
    "- Rule_Learning\n",
    "- Theory\n",
    "在该数据集中，每一篇论文至少引用了该数据集里面另外一篇论文或者被另外一篇论文所引用，数据集总共有2708篇`papers`。\n",
    "\n",
    "在消除停词以及除去文档频率小于10的词汇，最终词汇表中有1433个词汇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的库\n",
    "import itertools\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import urllib\n",
    "from collections import namedtuple\n",
    " \n",
    "import numpy as np\n",
    "import scipy.sparse as sp #邻接矩阵用稀疏矩阵形式存储 节省空间\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = namedtuple('Data', ['x', 'y', 'adjacency', 'train_mask', 'val_mask', 'test_mask'])\n",
    " \n",
    "def tensor_from_numpy(x, device): #将数据从数组格式转换为tensor格式 并转移到相关设备上\n",
    "    return torch.from_numpy(x).to(device)\n",
    " \n",
    "class CoraData(object):\n",
    "    #数据集下载链接\n",
    "    download_url = \"https://raw.githubusercontent.com/kimiyoung/planetoid/master/data\"\n",
    "    #数据集中包含的文件名\n",
    "    filenames = [\"ind.cora.{}\".format(name) for name in\n",
    "                 ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']]\n",
    " \n",
    "    def __init__(self, data_root=\"cora\", rebuild=False):\n",
    "        \"\"\"Cora数据，包括数据下载，处理，加载等功能\n",
    "        当数据的缓存文件存在时，将使用缓存文件，否则将下载、进行处理，并缓存到磁盘\n",
    "        处理之后的数据可以通过属性 .data 获得，它将返回一个数据对象，包括如下几部分：\n",
    "            * x: 节点的特征，维度为 2708 * 1433，类型为 np.ndarray\n",
    "            * y: 节点的标签，总共包括7个类别，类型为 np.ndarray\n",
    "            * adjacency: 邻接矩阵，维度为 2708 * 2708，类型为 scipy.sparse.coo.coo_matrix\n",
    "            * train_mask: 训练集掩码向量，维度为 2708，当节点属于训练集时，相应位置为True，否则False\n",
    "            * val_mask: 验证集掩码向量，维度为 2708，当节点属于验证集时，相应位置为True，否则False\n",
    "            * test_mask: 测试集掩码向量，维度为 2708，当节点属于测试集时，相应位置为True，否则False\n",
    "        Args:\n",
    "        -------\n",
    "            data_root: string, optional\n",
    "                存放数据的目录，原始数据路径: {data_root}/raw\n",
    "                缓存数据路径: {data_root}/processed_cora.pkl\n",
    "            rebuild: boolean, optional\n",
    "                是否需要重新构建数据集，当设为True时，如果存在缓存数据也会重建数据\n",
    "        \"\"\"\n",
    "        self.data_root = data_root\n",
    "        save_file = osp.join(self.data_root, \"processed_cora.pkl\")\n",
    "        if osp.exists(save_file) and not rebuild: #使用缓存数据\n",
    "            print(\"Using Cached file: {}\".format(save_file))\n",
    "            self._data = pickle.load(open(save_file, \"rb\"))\n",
    "        else:\n",
    "            self.maybe_download() #下载或使用原始数据集\n",
    "            self._data = self.process_data() #数据预处理\n",
    "            with open(save_file, \"wb\") as f: #把处理好的数据保存为缓存文件.pkl 下次直接使用\n",
    "                pickle.dump(self.data, f)\n",
    "            print(\"Cached file: {}\".format(save_file))\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"返回Data数据对象，包括x, y, adjacency, train_mask, val_mask, test_mask\"\"\"\n",
    "        return self._data\n",
    " \n",
    "    def process_data(self):\n",
    "        \"\"\"\n",
    "        处理数据，得到节点特征和标签，邻接矩阵，训练集、验证集以及测试集\n",
    "        引用自：https://github.com/rusty1s/pytorch_geometric\n",
    "        \"\"\"\n",
    "        print(\"Process data ...\")\n",
    "        #读取下载的数据文件\n",
    "        _, tx, allx, y, ty, ally, graph, test_index = [self.read_data(\n",
    "            osp.join(self.data_root, \"raw\", name)) for name in self.filenames]\n",
    "        \n",
    "        train_index = np.arange(y.shape[0]) #训练集索引\n",
    "        val_index = np.arange(y.shape[0], y.shape[0] + 500)#验证集索引\n",
    "        sorted_test_index = sorted(test_index) #测试集索引\n",
    " \n",
    "        x = np.concatenate((allx, tx), axis=0) #节点特征 N*D 2708*1433\n",
    "        y = np.concatenate((ally, ty), axis=0).argmax(axis=1)#节点对应的标签 2708\n",
    " \n",
    "        x[test_index] = x[sorted_test_index]\n",
    "        y[test_index] = y[sorted_test_index]\n",
    "        num_nodes = x.shape[0] #节点数/数据量 2708\n",
    "        \n",
    "        #训练、验证、测试集掩码\n",
    "        #初始化为0\n",
    "        train_mask = np.zeros(num_nodes, dtype=np.bool)\n",
    "        val_mask = np.zeros(num_nodes, dtype=np.bool)\n",
    "        test_mask = np.zeros(num_nodes, dtype=np.bool)\n",
    "        \n",
    "        train_mask[train_index] = True\n",
    "        val_mask[val_index] = True\n",
    "        test_mask[test_index] = True\n",
    "        \n",
    "        #构建邻接矩阵\n",
    "        adjacency = self.build_adjacency(graph)\n",
    "        print(\"Node's feature shape: \", x.shape) #（N*D）\n",
    "        print(\"Node's label shape: \", y.shape)#(N,)\n",
    "        print(\"Adjacency's shape: \", adjacency.shape) #(N,N)\n",
    "        #训练、验证、测试集各自的大小\n",
    "        print(\"Number of training nodes: \", train_mask.sum())\n",
    "        print(\"Number of validation nodes: \", val_mask.sum())\n",
    "        print(\"Number of test nodes: \", test_mask.sum())\n",
    " \n",
    "        return Data(x=x, y=y, adjacency=adjacency,\n",
    "                    train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n",
    " \n",
    "    def maybe_download(self):\n",
    "        #原始数据保存路径\n",
    "        save_path = os.path.join(self.data_root, \"raw\")\n",
    "        #下载相应的文件\n",
    "        for name in self.filenames:\n",
    "            if not osp.exists(osp.join(save_path, name)):\n",
    "                self.download_data(\n",
    "                    \"{}/{}\".format(self.download_url, name), save_path)\n",
    " \n",
    "    @staticmethod\n",
    "    def build_adjacency(adj_dict):\n",
    "        \"\"\"根据下载的邻接表创建邻接矩阵\"\"\"\n",
    "        edge_index = []\n",
    "        num_nodes = len(adj_dict)\n",
    "        for src, dst in adj_dict.items():\n",
    "            edge_index.extend([src, v] for v in dst)\n",
    "            edge_index.extend([v, src] for v in dst)\n",
    "        # 去除重复的边\n",
    "        edge_index = list(k for k, _ in itertools.groupby(sorted(edge_index)))\n",
    "        edge_index = np.asarray(edge_index)\n",
    "        #稀疏矩阵 存储非0值 节省空间\n",
    "        adjacency = sp.coo_matrix((np.ones(len(edge_index)), \n",
    "                                   (edge_index[:, 0], edge_index[:, 1])),\n",
    "                    shape=(num_nodes, num_nodes), dtype=\"float32\")\n",
    "        return adjacency\n",
    " \n",
    "    @staticmethod\n",
    "    def read_data(path):\n",
    "        \"\"\"使用不同的方式读取原始数据以进一步处理\"\"\"\n",
    "        name = osp.basename(path)\n",
    "        if name == \"ind.cora.test.index\":\n",
    "            out = np.genfromtxt(path, dtype=\"int64\")\n",
    "            return out\n",
    "        else:\n",
    "            out = pickle.load(open(path, \"rb\"), encoding=\"latin1\")\n",
    "            out = out.toarray() if hasattr(out, \"toarray\") else out\n",
    "            return out\n",
    " \n",
    "    @staticmethod\n",
    "    def download_data(url, save_path):\n",
    "        \"\"\"数据下载工具，当原始数据不存在时将会进行下载\"\"\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        data = urllib.request.urlopen(url)\n",
    "        filename = os.path.split(url)[-1]\n",
    " \n",
    "        with open(os.path.join(save_path, filename), 'wb') as f:\n",
    "            f.write(data.read())\n",
    " \n",
    "        return True\n",
    " \n",
    "    @staticmethod\n",
    "    def normalization(adjacency):\n",
    "        \"\"\"计算 L=D^-0.5 * (A+I) * D^-0.5\"\"\"\n",
    "        adjacency += sp.eye(adjacency.shape[0])    # 增加自连接 不仅考虑邻接节点特征 还考虑节点自身的特征\n",
    "        degree = np.array(adjacency.sum(1)) #此时的度矩阵的对角线的值 为 邻接矩阵 按行求和\n",
    "        d_hat = sp.diags(np.power(degree, -0.5).flatten()) #对度矩阵对角线的值取-0.5次方 再转换为对角矩阵\n",
    "        return d_hat.dot(adjacency).dot(d_hat).tocoo() #归一化的拉普拉斯矩阵 稀疏存储 节省空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, use_bias=True):\n",
    "        \"\"\"图卷积：L*X*\\theta\n",
    "        Args:\n",
    "        ----------\n",
    "            input_dim: int\n",
    "                节点输入特征的维度 D\n",
    "            output_dim: int\n",
    "                输出特征维度 D‘\n",
    "            use_bias : bool, optional\n",
    "                是否使用偏置\n",
    "        \"\"\"\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_bias = use_bias\n",
    "        #定义GCN层的权重矩阵\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        if self.use_bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters() #使用自定义的参数初始化方式\n",
    " \n",
    "    def reset_parameters(self):\n",
    "        #自定义参数初始化方式\n",
    "        #权重参数初始化方式\n",
    "        init.kaiming_uniform_(self.weight)\n",
    "        if self.use_bias: #偏置参数初始化为0\n",
    "            init.zeros_(self.bias)\n",
    " \n",
    "    def forward(self, adjacency, input_feature):\n",
    "        \"\"\"邻接矩阵是稀疏矩阵，因此在计算时使用稀疏矩阵乘法\n",
    "    \n",
    "        Args: \n",
    "        -------\n",
    "            adjacency: torch.sparse.FloatTensor\n",
    "                邻接矩阵\n",
    "            input_feature: torch.Tensor\n",
    "                输入特征\n",
    "        \"\"\"\n",
    "        support = torch.mm(input_feature, self.weight) #XW (N,D');X (N,D);W (D,D')  \n",
    "        output = torch.sparse.mm(adjacency, support) #(N,D')\n",
    "        if self.use_bias:\n",
    "            output += self.bias\n",
    "        return output\n",
    " \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + str(self.input_dim) + ' -> ' \\\n",
    "            + str(self.output_dim) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GcnNet(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个包含两层GraphConvolution的模型\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=1433):\n",
    "        super(GcnNet, self).__init__()\n",
    "        self.gcn1 = GraphConvolution(input_dim, 16)\n",
    "        self.gcn2 = GraphConvolution(16, 7)\n",
    "    \n",
    "    def forward(self, adjacency, feature):\n",
    "        h = F.relu(self.gcn1(adjacency, feature)) #(N,1433)->(N,16)\n",
    "        logits = self.gcn2(adjacency, h) #(N,16)->(N,7)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数定义\n",
    "LEARNING_RATE = 0.1  #学习率\n",
    "WEIGHT_DACAY = 5e-4 #正则化系数\n",
    "EPOCHS = 200       #完整遍历训练集的次数 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" #设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cached file: cora\\processed_cora.pkl\n"
     ]
    }
   ],
   "source": [
    "# 加载数据，并转换为torch.Tensor\n",
    "dataset = CoraData().data\n",
    "node_feature = dataset.x / dataset.x.sum(1, keepdims=True)  # 归一化数据，使得每一行和为1\n",
    "tensor_x = tensor_from_numpy(node_feature, DEVICE)\n",
    "tensor_y = tensor_from_numpy(dataset.y, DEVICE)\n",
    "tensor_train_mask = tensor_from_numpy(dataset.train_mask, DEVICE)\n",
    "tensor_val_mask = tensor_from_numpy(dataset.val_mask, DEVICE)\n",
    "tensor_test_mask = tensor_from_numpy(dataset.test_mask, DEVICE)\n",
    "normalize_adjacency = CoraData.normalization(dataset.adjacency)   # 规范化邻接矩阵\n",
    " \n",
    "num_nodes, input_dim = node_feature.shape #（N,D）\n",
    "#转换为稀疏表示 加速运算 节省空间\n",
    "indices = torch.from_numpy(np.asarray([normalize_adjacency.row, normalize_adjacency.col]).astype('int64')).long()\n",
    "values = torch.from_numpy(normalize_adjacency.data.astype(np.float32))\n",
    "tensor_adjacency = torch.sparse.FloatTensor(indices, values, (num_nodes, num_nodes)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义：Model, Loss, Optimizer\n",
    "model = GcnNet(input_dim).to(DEVICE) #如果gpu>1 用DataParallel()包裹 单机多卡 数据并行\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE) #多分类交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DACAY) #Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练主体函数\n",
    "def train():\n",
    "    loss_history = []\n",
    "    val_acc_history = []\n",
    "    model.train() #训练模式\n",
    "    train_y = tensor_y[tensor_train_mask] #训练节点的标签\n",
    "    for epoch in range(EPOCHS): #完整遍历一遍训练集 一个epoch做一次更新\n",
    "        logits = model(tensor_adjacency, tensor_x)  # 所有数据前向传播 （N,7）\n",
    "        train_mask_logits = logits[tensor_train_mask]   # 只选择训练节点进行监督\n",
    "        loss = criterion(train_mask_logits, train_y)    # 计算损失值\n",
    "        optimizer.zero_grad()  #清空梯度\n",
    "        loss.backward()     # 反向传播计算参数的梯度\n",
    "        optimizer.step()    # 使用优化方法进行梯度更新\n",
    "        train_acc, _, _ = test(tensor_train_mask)     # 计算当前模型训练集上的准确率\n",
    "        val_acc, _, _ = test(tensor_val_mask)     # 计算当前模型在验证集上的准确率\n",
    "        # 记录训练过程中损失值和准确率的变化，用于画图\n",
    "        loss_history.append(loss.item())\n",
    "        val_acc_history.append(val_acc.item())\n",
    "        print(\"Epoch {:03d}: Loss {:.4f}, TrainAcc {:.4}, ValAcc {:.4f}\".format(\n",
    "            epoch, loss.item(), train_acc.item(), val_acc.item()))\n",
    "    \n",
    "    return loss_history, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试函数\n",
    "def test(mask):\n",
    "    model.eval() #测试模式\n",
    "    with torch.no_grad(): #关闭求导\n",
    "        logits = model(tensor_adjacency, tensor_x) #所有数据作前向传播\n",
    "        test_mask_logits = logits[mask] #取出相应数据集对应的部分\n",
    "        predict_y = test_mask_logits.max(1)[1] #按行取argmax 得到预测的标签\n",
    "        accuarcy = torch.eq(predict_y, tensor_y[mask]).float().mean() #计算准确率\n",
    "    return accuarcy, test_mask_logits.cpu().numpy(), tensor_y[mask].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化训练集损失和验证集准确率变化\n",
    "def plot_loss_with_acc(loss_history, val_acc_history):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.plot(range(len(loss_history)), loss_history, c=np.array([255, 71, 90]) / 255.)\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    ax2 = fig.add_subplot(111, sharex=ax1, frameon=False)\n",
    "    ax2.plot(range(len(val_acc_history)), val_acc_history, c=np.array([79, 179, 255]) / 255.)\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    plt.ylabel('ValAcc')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Training Loss & Validation Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss 1.9453, TrainAcc 0.3214, ValAcc 0.2360\n",
      "Epoch 001: Loss 1.8614, TrainAcc 0.45, ValAcc 0.4060\n",
      "Epoch 002: Loss 1.7587, TrainAcc 0.7143, ValAcc 0.4020\n",
      "Epoch 003: Loss 1.6340, TrainAcc 0.7929, ValAcc 0.5060\n",
      "Epoch 004: Loss 1.4844, TrainAcc 0.8857, ValAcc 0.6820\n",
      "Epoch 005: Loss 1.3330, TrainAcc 0.9071, ValAcc 0.7380\n",
      "Epoch 006: Loss 1.1775, TrainAcc 0.9357, ValAcc 0.7520\n",
      "Epoch 007: Loss 1.0319, TrainAcc 0.9643, ValAcc 0.7540\n",
      "Epoch 008: Loss 0.8849, TrainAcc 0.95, ValAcc 0.7440\n",
      "Epoch 009: Loss 0.7573, TrainAcc 0.9429, ValAcc 0.7360\n",
      "Epoch 010: Loss 0.6491, TrainAcc 0.95, ValAcc 0.7660\n",
      "Epoch 011: Loss 0.5509, TrainAcc 0.9786, ValAcc 0.7840\n",
      "Epoch 012: Loss 0.4718, TrainAcc 0.9857, ValAcc 0.7860\n",
      "Epoch 013: Loss 0.4077, TrainAcc 0.9929, ValAcc 0.7700\n",
      "Epoch 014: Loss 0.3568, TrainAcc 0.9857, ValAcc 0.7760\n",
      "Epoch 015: Loss 0.3163, TrainAcc 0.9929, ValAcc 0.7800\n",
      "Epoch 016: Loss 0.2845, TrainAcc 1.0, ValAcc 0.7840\n",
      "Epoch 017: Loss 0.2620, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 018: Loss 0.2436, TrainAcc 1.0, ValAcc 0.7800\n",
      "Epoch 019: Loss 0.2295, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 020: Loss 0.2221, TrainAcc 1.0, ValAcc 0.7860\n",
      "Epoch 021: Loss 0.2137, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 022: Loss 0.2078, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 023: Loss 0.2038, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 024: Loss 0.1973, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 025: Loss 0.1919, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 026: Loss 0.1857, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 027: Loss 0.1786, TrainAcc 1.0, ValAcc 0.7840\n",
      "Epoch 028: Loss 0.1719, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 029: Loss 0.1654, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 030: Loss 0.1585, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 031: Loss 0.1532, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 032: Loss 0.1479, TrainAcc 1.0, ValAcc 0.7840\n",
      "Epoch 033: Loss 0.1442, TrainAcc 1.0, ValAcc 0.7860\n",
      "Epoch 034: Loss 0.1407, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 035: Loss 0.1383, TrainAcc 1.0, ValAcc 0.7860\n",
      "Epoch 036: Loss 0.1358, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 037: Loss 0.1342, TrainAcc 1.0, ValAcc 0.7840\n",
      "Epoch 038: Loss 0.1324, TrainAcc 1.0, ValAcc 0.7860\n",
      "Epoch 039: Loss 0.1312, TrainAcc 1.0, ValAcc 0.7800\n",
      "Epoch 040: Loss 0.1297, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 041: Loss 0.1289, TrainAcc 1.0, ValAcc 0.7800\n",
      "Epoch 042: Loss 0.1288, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 043: Loss 0.1306, TrainAcc 0.9929, ValAcc 0.7900\n",
      "Epoch 044: Loss 0.1316, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 045: Loss 0.1265, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 046: Loss 0.1195, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 047: Loss 0.1213, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 048: Loss 0.1219, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 049: Loss 0.1170, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 050: Loss 0.1190, TrainAcc 1.0, ValAcc 0.8060\n",
      "Epoch 051: Loss 0.1207, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 052: Loss 0.1172, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 053: Loss 0.1179, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 054: Loss 0.1196, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 055: Loss 0.1170, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 056: Loss 0.1158, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 057: Loss 0.1172, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 058: Loss 0.1155, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 059: Loss 0.1140, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 060: Loss 0.1150, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 061: Loss 0.1145, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 062: Loss 0.1132, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 063: Loss 0.1139, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 064: Loss 0.1143, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 065: Loss 0.1135, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 066: Loss 0.1135, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 067: Loss 0.1141, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 068: Loss 0.1138, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 069: Loss 0.1132, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 070: Loss 0.1134, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 071: Loss 0.1137, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 072: Loss 0.1132, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 073: Loss 0.1129, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 074: Loss 0.1133, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 075: Loss 0.1133, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 076: Loss 0.1132, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 077: Loss 0.1131, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 078: Loss 0.1135, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 079: Loss 0.1136, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 080: Loss 0.1135, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 081: Loss 0.1133, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 082: Loss 0.1135, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 083: Loss 0.1136, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 084: Loss 0.1136, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 085: Loss 0.1134, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 086: Loss 0.1135, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 087: Loss 0.1137, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 088: Loss 0.1138, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 089: Loss 0.1139, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 090: Loss 0.1138, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 091: Loss 0.1139, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 092: Loss 0.1139, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 093: Loss 0.1140, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 094: Loss 0.1141, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 095: Loss 0.1141, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 096: Loss 0.1142, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 097: Loss 0.1142, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 098: Loss 0.1142, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 099: Loss 0.1143, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 100: Loss 0.1143, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 101: Loss 0.1144, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 102: Loss 0.1144, TrainAcc 1.0, ValAcc 0.8060\n",
      "Epoch 103: Loss 0.1144, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 104: Loss 0.1145, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 105: Loss 0.1146, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 106: Loss 0.1146, TrainAcc 1.0, ValAcc 0.8060\n",
      "Epoch 107: Loss 0.1146, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 108: Loss 0.1147, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 109: Loss 0.1147, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 110: Loss 0.1147, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 111: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 112: Loss 0.1149, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 113: Loss 0.1151, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 114: Loss 0.1152, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 115: Loss 0.1156, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 116: Loss 0.1159, TrainAcc 1.0, ValAcc 0.8060\n",
      "Epoch 117: Loss 0.1166, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 118: Loss 0.1170, TrainAcc 1.0, ValAcc 0.8060\n",
      "Epoch 119: Loss 0.1172, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 120: Loss 0.1162, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 121: Loss 0.1145, TrainAcc 1.0, ValAcc 0.8000\n",
      "Epoch 122: Loss 0.1129, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 123: Loss 0.1134, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 124: Loss 0.1155, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 125: Loss 0.1174, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 126: Loss 0.1184, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 127: Loss 0.1178, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 128: Loss 0.1161, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 129: Loss 0.1140, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 130: Loss 0.1136, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 131: Loss 0.1146, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 132: Loss 0.1157, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 133: Loss 0.1159, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 134: Loss 0.1153, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 135: Loss 0.1150, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 136: Loss 0.1151, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 137: Loss 0.1156, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 138: Loss 0.1159, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 139: Loss 0.1157, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 140: Loss 0.1153, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 141: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 142: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 143: Loss 0.1149, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 144: Loss 0.1152, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 145: Loss 0.1152, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 146: Loss 0.1152, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 147: Loss 0.1152, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 148: Loss 0.1151, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 149: Loss 0.1152, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 150: Loss 0.1152, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 151: Loss 0.1153, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 152: Loss 0.1151, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 153: Loss 0.1150, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 154: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 155: Loss 0.1147, TrainAcc 1.0, ValAcc 0.7960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156: Loss 0.1149, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 157: Loss 0.1151, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 158: Loss 0.1154, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 159: Loss 0.1154, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 160: Loss 0.1155, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 161: Loss 0.1153, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 162: Loss 0.1153, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 163: Loss 0.1151, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 164: Loss 0.1153, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 165: Loss 0.1156, TrainAcc 1.0, ValAcc 0.8040\n",
      "Epoch 166: Loss 0.1161, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 167: Loss 0.1164, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 168: Loss 0.1162, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 169: Loss 0.1154, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 170: Loss 0.1143, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 171: Loss 0.1137, TrainAcc 1.0, ValAcc 0.7880\n",
      "Epoch 172: Loss 0.1141, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 173: Loss 0.1150, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 174: Loss 0.1161, TrainAcc 1.0, ValAcc 0.8020\n",
      "Epoch 175: Loss 0.1167, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 176: Loss 0.1172, TrainAcc 1.0, ValAcc 0.7980\n",
      "Epoch 177: Loss 0.1174, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 178: Loss 0.1174, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 179: Loss 0.1169, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 180: Loss 0.1156, TrainAcc 1.0, ValAcc 0.7860\n",
      "Epoch 181: Loss 0.1141, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 182: Loss 0.1134, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 183: Loss 0.1145, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 184: Loss 0.1164, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 185: Loss 0.1179, TrainAcc 1.0, ValAcc 0.7860\n",
      "Epoch 186: Loss 0.1179, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 187: Loss 0.1161, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 188: Loss 0.1141, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 189: Loss 0.1135, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 190: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7900\n",
      "Epoch 191: Loss 0.1162, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 192: Loss 0.1162, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 193: Loss 0.1154, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 194: Loss 0.1146, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 195: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 196: Loss 0.1155, TrainAcc 1.0, ValAcc 0.7940\n",
      "Epoch 197: Loss 0.1156, TrainAcc 1.0, ValAcc 0.7960\n",
      "Epoch 198: Loss 0.1152, TrainAcc 1.0, ValAcc 0.7920\n",
      "Epoch 199: Loss 0.1148, TrainAcc 1.0, ValAcc 0.7960\n",
      "Test accuarcy:  0.8130000233650208\n"
     ]
    }
   ],
   "source": [
    "loss, val_acc = train()#每个epoch 模型在训练集上的loss 和验证集上的准确率\n",
    "#计算最后训练好的模型在测试集上准确率\n",
    "test_acc, test_logits, test_label = test(tensor_test_mask)\n",
    "print(\"Test accuarcy: \", test_acc.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_with_acc(loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.5106515 ,  0.59341556, -0.19808292, ..., -0.734635  ,\n",
       "         -0.13036597, -0.29282653],\n",
       "        [-0.50656515, -0.42324293,  4.490959  , ..., -0.40697753,\n",
       "         -1.4807918 , -0.8542136 ],\n",
       "        [-0.48957846,  1.0379071 ,  2.1165938 , ..., -0.86578727,\n",
       "         -1.3988242 , -1.7559838 ],\n",
       "        ...,\n",
       "        [ 2.100123  ,  2.5581636 , -4.1391435 , ..., -3.5364842 ,\n",
       "          1.1836109 ,  0.6337291 ],\n",
       "        [-0.91950095, -0.04575482, -0.24669635, ...,  0.71824455,\n",
       "         -2.111446  , -1.7071737 ],\n",
       "        [-0.90880615,  0.08546245, -0.09092414, ...,  0.37782782,\n",
       "         -1.6366246 , -1.7406329 ]], dtype=float32),\n",
       " array([3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2,\n",
       "        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 4, 4, 4,\n",
       "        4, 1, 1, 3, 1, 0, 3, 0, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 1, 6, 6, 3, 0, 0,\n",
       "        5, 0, 5, 0, 3, 5, 3, 0, 0, 6, 0, 6, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 2, 2, 2, 4, 4, 4, 0, 3, 3, 2, 5, 5, 5, 5, 6, 5, 5, 5, 5, 0,\n",
       "        4, 4, 4, 0, 0, 5, 0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 3, 0, 0, 0,\n",
       "        3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        6, 6, 5, 6, 6, 3, 5, 5, 5, 0, 5, 0, 4, 4, 3, 3, 3, 2, 2, 1, 3, 3,\n",
       "        3, 3, 3, 3, 5, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 6, 3, 6,\n",
       "        0, 5, 0, 0, 4, 0, 6, 5, 5, 0, 1, 3, 3, 5, 6, 5, 3, 3, 4, 3, 3, 3,\n",
       "        3, 3, 4, 3, 3, 4, 3, 1, 1, 0, 1, 0, 6, 0, 0, 0, 0, 0, 0, 0, 5, 0,\n",
       "        5, 5, 5, 3, 3, 3, 3, 3, 0, 0, 0, 2, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1, 0, 1, 3, 1, 1, 1, 1, 1, 0, 0, 0, 5, 5, 5, 5,\n",
       "        3, 5, 1, 1, 3, 6, 6, 5, 6, 2, 3, 3, 0, 3, 3, 3, 4, 4, 4, 4, 3, 3,\n",
       "        3, 4, 3, 3, 4, 0, 6, 0, 6, 6, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3,\n",
       "        3, 3, 5, 6, 3, 4, 6, 0, 0, 6, 6, 6, 6, 6, 3, 3, 6, 6, 5, 2, 1, 2,\n",
       "        1, 0, 0, 6, 6, 2, 3, 3, 5, 0, 0, 0, 0, 0, 5, 5, 0, 3, 5, 0, 6, 3,\n",
       "        6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 6, 1, 0, 3, 3,\n",
       "        3, 3, 3, 6, 1, 0, 2, 2, 4, 4, 4, 4, 4, 5, 6, 3, 3, 0, 0, 0, 0, 5,\n",
       "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 0, 3, 4, 4, 4, 1, 1, 3, 1, 1, 5, 1,\n",
       "        3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 5, 5, 5, 5, 5, 0, 5, 3, 0, 6, 2,\n",
       "        0, 5, 3, 3, 5, 5, 5, 5, 5, 4, 4, 0, 4, 0, 4, 0, 3, 4, 4, 4, 1, 3,\n",
       "        3, 3, 3, 3, 4, 2, 3, 3, 3, 0, 0, 2, 3, 3, 3, 3, 1, 1, 3, 0, 1, 4,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 2, 4, 4, 4, 3, 3, 3, 4, 0, 3, 3, 3,\n",
       "        3, 0, 3, 3, 4, 4, 4, 4, 4, 4, 0, 4, 3, 2, 0, 3, 4, 5, 0, 2, 2, 3,\n",
       "        3, 3, 3, 3, 2, 3, 5, 5, 4, 1, 4, 4, 4, 3, 4, 4, 0, 4, 4, 4, 5, 2,\n",
       "        2, 2, 2, 4, 6, 6, 6, 6, 3, 4, 4, 4, 1, 3, 0, 3, 3, 5, 0, 2, 3, 3,\n",
       "        3, 3, 3, 2, 4, 4, 0, 0, 3, 2, 6, 6, 0, 3, 3, 3, 5, 1, 3, 4, 4, 2,\n",
       "        4, 4, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 6, 6,\n",
       "        5, 6, 6, 3, 2, 6, 3, 4, 4, 4, 2, 6, 6, 0, 0, 3, 0, 4, 4, 3, 2, 3,\n",
       "        1, 6, 6, 5, 3, 4, 3, 5, 3, 1, 1, 3, 4, 5, 2, 3, 3, 3, 4, 5, 4, 0,\n",
       "        3, 3, 0, 2, 1, 1, 5, 2, 3, 3, 5, 0, 2, 3, 2, 2, 5, 5, 4, 3, 4, 3,\n",
       "        2, 2, 4, 2, 4, 5, 5, 3, 2, 3, 1, 0, 3, 3, 4, 5, 4, 3, 3, 3, 3, 3,\n",
       "        0, 1, 2, 4, 4, 4, 3, 3, 3, 5, 2, 3, 2, 2, 2, 3, 2, 2, 0, 4, 4, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 2, 3, 4, 1, 2, 5, 4,\n",
       "        3, 3, 3, 1, 5, 3, 4, 3, 2, 2, 1, 3, 3, 3, 3, 3, 6, 3, 3, 3, 6, 3,\n",
       "        3, 3, 2, 3, 2, 4, 2, 4, 2, 2, 1, 5, 6, 4, 3, 3, 3, 2, 5, 3, 3, 4,\n",
       "        3, 3, 3, 3, 3, 4, 6, 0, 3, 2, 2, 2, 5, 4, 4, 4, 4, 6, 3, 2, 2, 0,\n",
       "        2, 2, 2, 2, 2, 3, 4, 4, 4, 3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "        3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 2, 6, 2, 3, 3, 4, 4, 3, 3,\n",
       "        3, 3, 3, 3, 0, 3, 3, 3, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logits, test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是完整的定义图网络，处理图数据并进行训练的过程，实际上，有一个图神经网络库帮我们实现了图网络的结构，并且包含了`Cora`数据集，这个库就是`pytorch_geometric(PyG)`,接下来我们使用库来实现上面的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using exist file ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1317\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1243\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    937\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 938\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    939\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5721240fd8a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/tmp/Cora'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Cora'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch_geometric\\datasets\\planetoid.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, name, transform, pre_transform)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPlanetoid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     51\u001b[0m                  pre_filter=None):\n\u001b[0;32m     52\u001b[0m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[1;32m---> 53\u001b[1;33m                                               pre_filter)\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'download'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'process'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\dataset.py\u001b[0m in \u001b[0;36m_download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch_geometric\\datasets\\planetoid.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_file_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\site-packages\\torch_geometric\\data\\download.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, folder, log)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1360\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1319\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。>"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
